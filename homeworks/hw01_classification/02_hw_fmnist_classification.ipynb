{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDsVMGiVgSq2"
      },
      "source": [
        "## Классификация FashionMNIST\n",
        "\n",
        "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/s/girafe_ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "3isBRG6PgSq6"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import pyplot as plt\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision.datasets import FashionMNIST\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "EQAKWzJMfAvL"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "def get_predictions(model, eval_data, step=10):\n",
        "\n",
        "    predicted_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx in range(0, len(eval_data), step):\n",
        "            y_predicted = model(eval_data[idx : idx + step].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    predicted_labels = \",\".join([str(x.item()) for x in list(predicted_labels)])\n",
        "    return predicted_labels\n",
        "\n",
        "\n",
        "def get_accuracy(model, data_loader):\n",
        "    predicted_labels = []\n",
        "    real_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            y_predicted = model(batch[0].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "            real_labels.append(batch[1])\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    real_labels = torch.cat(real_labels)\n",
        "    accuracy_score = (predicted_labels == real_labels).type(torch.FloatTensor).mean()\n",
        "    return accuracy_score\n",
        "\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH413P--fAvN"
      },
      "source": [
        "Загрузите файл `hw_overfitting_data_dict.npy` (ссылка есть на странице с заданием), он понадобится для генерации посылок. Код ниже может его загрузить (но в случае возникновения ошибки скачайте и загрузите его вручную).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jwCqo4e5fAvN",
        "outputId": "7b42dd34-8a05-4c28-9f14-17c6f913c044",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-10 12:27:34--  https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict [following]\n",
            "--2025-04-10 12:27:34--  https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6272446 (6.0M) [application/octet-stream]\n",
            "Saving to: ‘hw_overfitting_data_dict.npy’\n",
            "\n",
            "hw_overfitting_data 100%[===================>]   5.98M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2025-04-10 12:27:34 (65.2 MB/s) - ‘hw_overfitting_data_dict.npy’ saved [6272446/6272446]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict -O hw_overfitting_data_dict.npy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "LrNbhhc3fAvO"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeA6Q5-CgSq7"
      },
      "source": [
        "Вернемся к задаче распознавания простых изображений, рассмотренной ранее. Но теперь будем работать с набором данных [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). В данном задании воспользуемся всем датасетом целиком.\n",
        "\n",
        "__Ваша первая задача: реализовать весь пайплан обучения модели и добиться качества $\\geq 88.5\\%$ на тестовой выборке.__\n",
        "\n",
        "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбукам с предыдущих занятий."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "JGsFYM04fAvP"
      },
      "outputs": [],
      "source": [
        "CUDA_DEVICE_ID = 0  # change if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "nPG1KbQAgl8b"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "device = (\n",
        "    torch.device(f\"cuda:{CUDA_DEVICE_ID}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        ")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "aYcL28OsgSq8",
        "outputId": "5ce293d1-2ad1-4c98-f41c-bc606e0c17db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Image label: 7')"
            ]
          },
          "metadata": {},
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "train_fmnist_data = FashionMNIST(\n",
        "    \".\", train=True, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "test_fmnist_data = FashionMNIST(\n",
        "    \".\", train=False, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_fmnist_data, batch_size=32, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_fmnist_data, batch_size=32, shuffle=False, num_workers=2\n",
        ")\n",
        "\n",
        "random_batch = next(iter(train_data_loader))\n",
        "_image, _label = random_batch[0][0], random_batch[1][0]\n",
        "plt.figure()\n",
        "plt.imshow(_image.reshape(28, 28))\n",
        "plt.title(f\"Image label: {_label}\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6jWRv1rgSq8"
      },
      "source": [
        "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 88.5% accuracy.\n",
        "\n",
        "__Внимание, ваша модель должна быть представлена именно переменной `model_task_1`. На вход ей должен приходить тензор размерностью (1, 28, 28).__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "BcyEFX-RgSq8"
      },
      "outputs": [],
      "source": [
        "# Creating model instance\n",
        "# Определение модели\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "\n",
        "        # Свёрточный слой\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=96, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Полносвязные слои\n",
        "        self.fc1 = nn.Linear(96 * 14 * 14, 96 * 14 * 14)\n",
        "        self.fc2 = nn.Linear(96 * 14 * 14, 1000)\n",
        "        self.fc3 = nn.Linear(1000, 128)\n",
        "        self.fc4 = nn.Linear(128, 10)  # 10 классов для MNIST\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Прямой проход через свёрточный блок\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "\n",
        "        # Преобразование тензора в одномерный вектор\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "\n",
        "        # Проход через полносвязные слои\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "model_task_1 = SimpleCNN()\n",
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAoLV4dkoy5M"
      },
      "source": [
        "Не забудьте перенести модель на выбранный `device`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "Xas9SIXDoxvZ",
        "outputId": "178c55fd-2a25-4322-cb71-640310c5fd89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleCNN(\n",
              "  (conv1): Conv2d(1, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=18816, out_features=18816, bias=True)\n",
              "  (fc2): Linear(in_features=18816, out_features=1000, bias=True)\n",
              "  (fc3): Linear(in_features=1000, out_features=128, bias=True)\n",
              "  (fc4): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "model_task_1.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pLRWysggSq9"
      },
      "source": [
        "Локальные тесты для проверки вашей модели доступны ниже:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qMQzo1ggSq9",
        "outputId": "b755dfe0-bbd4-423a-e4b8-45dc2fc4ae9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything seems fine!\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert model_task_1 is not None, \"Please, use `model_task_1` variable to store your model\"\n",
        "\n",
        "try:\n",
        "    x = random_batch[0].to(device)\n",
        "    y = random_batch[1].to(device)\n",
        "\n",
        "    # compute outputs given inputs, both are variables\n",
        "    y_predicted = model_task_1(x)\n",
        "except Exception as e:\n",
        "    print(\"Something is wrong with the model\")\n",
        "    raise e\n",
        "\n",
        "\n",
        "assert y_predicted.shape[-1] == 10, \"Model should predict 10 logits/probas\"\n",
        "\n",
        "print(\"Everything seems fine!\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suRmIPwIgSq9"
      },
      "source": [
        "Настройте параметры модели на обучающей выборке. Также рекомендуем поработать с `learning rate`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "YJnU14bdnZa_",
        "outputId": "20a595aa-2130-4ee1-df01-ab64f4f7fefa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [100/1875], Loss: 3.4920, Accuracy: 49.91%\n",
            "Epoch [1/10], Step [200/1875], Loss: 0.6535, Accuracy: 62.67%\n",
            "Epoch [1/10], Step [300/1875], Loss: 0.5580, Accuracy: 68.42%\n",
            "Epoch [1/10], Step [400/1875], Loss: 0.5108, Accuracy: 71.48%\n",
            "Epoch [1/10], Step [500/1875], Loss: 0.4517, Accuracy: 73.96%\n",
            "Epoch [1/10], Step [600/1875], Loss: 0.4429, Accuracy: 75.81%\n",
            "Epoch [1/10], Step [700/1875], Loss: 0.4494, Accuracy: 77.01%\n",
            "Epoch [1/10], Step [800/1875], Loss: 0.3970, Accuracy: 78.18%\n",
            "Epoch [1/10], Step [900/1875], Loss: 0.4060, Accuracy: 79.05%\n",
            "Epoch [1/10], Step [1000/1875], Loss: 0.4171, Accuracy: 79.62%\n",
            "Epoch [1/10], Step [1100/1875], Loss: 0.3900, Accuracy: 80.20%\n",
            "Epoch [1/10], Step [1200/1875], Loss: 0.3762, Accuracy: 80.77%\n",
            "Epoch [1/10], Step [1300/1875], Loss: 0.3594, Accuracy: 81.28%\n",
            "Epoch [1/10], Step [1400/1875], Loss: 0.3512, Accuracy: 81.70%\n",
            "Epoch [1/10], Step [1500/1875], Loss: 0.3258, Accuracy: 82.11%\n",
            "Epoch [1/10], Step [1600/1875], Loss: 0.3671, Accuracy: 82.43%\n",
            "Epoch [1/10], Step [1700/1875], Loss: 0.3345, Accuracy: 82.78%\n",
            "Epoch [1/10], Step [1800/1875], Loss: 0.3403, Accuracy: 83.07%\n",
            "Test Accuracy after Epoch 1: 87.35%\n",
            "\n",
            "Accuracy for class 0: 65.30%\n",
            "Accuracy for class 1: 95.20%\n",
            "Accuracy for class 2: 77.30%\n",
            "Accuracy for class 3: 91.50%\n",
            "Accuracy for class 4: 75.40%\n",
            "Accuracy for class 5: 97.50%\n",
            "Accuracy for class 6: 82.00%\n",
            "Accuracy for class 7: 97.60%\n",
            "Accuracy for class 8: 96.90%\n",
            "Accuracy for class 9: 94.80%\n",
            "Epoch [2/10], Step [100/1875], Loss: 0.3091, Accuracy: 88.69%\n",
            "Epoch [2/10], Step [200/1875], Loss: 0.3051, Accuracy: 89.20%\n",
            "Epoch [2/10], Step [300/1875], Loss: 0.2902, Accuracy: 89.39%\n",
            "Epoch [2/10], Step [400/1875], Loss: 0.2968, Accuracy: 89.39%\n",
            "Epoch [2/10], Step [500/1875], Loss: 0.3020, Accuracy: 89.31%\n",
            "Epoch [2/10], Step [600/1875], Loss: 0.2985, Accuracy: 89.39%\n",
            "Epoch [2/10], Step [700/1875], Loss: 0.2881, Accuracy: 89.49%\n",
            "Epoch [2/10], Step [800/1875], Loss: 0.2854, Accuracy: 89.45%\n",
            "Epoch [2/10], Step [900/1875], Loss: 0.3090, Accuracy: 89.39%\n",
            "Epoch [2/10], Step [1000/1875], Loss: 0.2910, Accuracy: 89.40%\n",
            "Epoch [2/10], Step [1100/1875], Loss: 0.2855, Accuracy: 89.43%\n",
            "Epoch [2/10], Step [1200/1875], Loss: 0.2698, Accuracy: 89.53%\n",
            "Epoch [2/10], Step [1300/1875], Loss: 0.2745, Accuracy: 89.56%\n",
            "Epoch [2/10], Step [1400/1875], Loss: 0.2700, Accuracy: 89.63%\n",
            "Epoch [2/10], Step [1500/1875], Loss: 0.2784, Accuracy: 89.69%\n",
            "Epoch [2/10], Step [1600/1875], Loss: 0.2593, Accuracy: 89.74%\n",
            "Epoch [2/10], Step [1700/1875], Loss: 0.3073, Accuracy: 89.69%\n",
            "Epoch [2/10], Step [1800/1875], Loss: 0.2665, Accuracy: 89.72%\n",
            "Test Accuracy after Epoch 2: 88.99%\n",
            "\n",
            "Accuracy for class 0: 92.50%\n",
            "Accuracy for class 1: 97.10%\n",
            "Accuracy for class 2: 85.40%\n",
            "Accuracy for class 3: 92.60%\n",
            "Accuracy for class 4: 83.40%\n",
            "Accuracy for class 5: 98.90%\n",
            "Accuracy for class 6: 53.80%\n",
            "Accuracy for class 7: 97.60%\n",
            "Accuracy for class 8: 97.40%\n",
            "Accuracy for class 9: 91.20%\n",
            "Epoch [3/10], Step [100/1875], Loss: 0.2373, Accuracy: 91.00%\n",
            "Epoch [3/10], Step [200/1875], Loss: 0.2425, Accuracy: 91.05%\n",
            "Epoch [3/10], Step [300/1875], Loss: 0.2299, Accuracy: 91.21%\n",
            "Epoch [3/10], Step [400/1875], Loss: 0.2353, Accuracy: 91.38%\n",
            "Epoch [3/10], Step [500/1875], Loss: 0.2466, Accuracy: 91.31%\n",
            "Epoch [3/10], Step [600/1875], Loss: 0.2626, Accuracy: 91.28%\n",
            "Epoch [3/10], Step [700/1875], Loss: 0.2407, Accuracy: 91.33%\n",
            "Epoch [3/10], Step [800/1875], Loss: 0.2426, Accuracy: 91.32%\n",
            "Epoch [3/10], Step [900/1875], Loss: 0.2140, Accuracy: 91.41%\n",
            "Epoch [3/10], Step [1000/1875], Loss: 0.2376, Accuracy: 91.42%\n",
            "Epoch [3/10], Step [1100/1875], Loss: 0.2478, Accuracy: 91.38%\n",
            "Epoch [3/10], Step [1200/1875], Loss: 0.2263, Accuracy: 91.45%\n",
            "Epoch [3/10], Step [1300/1875], Loss: 0.2619, Accuracy: 91.37%\n",
            "Epoch [3/10], Step [1400/1875], Loss: 0.2413, Accuracy: 91.37%\n",
            "Epoch [3/10], Step [1500/1875], Loss: 0.2684, Accuracy: 91.35%\n",
            "Epoch [3/10], Step [1600/1875], Loss: 0.2385, Accuracy: 91.33%\n",
            "Epoch [3/10], Step [1700/1875], Loss: 0.2181, Accuracy: 91.39%\n",
            "Epoch [3/10], Step [1800/1875], Loss: 0.2305, Accuracy: 91.41%\n",
            "Test Accuracy after Epoch 3: 88.93%\n",
            "\n",
            "Accuracy for class 0: 84.90%\n",
            "Accuracy for class 1: 97.70%\n",
            "Accuracy for class 2: 85.50%\n",
            "Accuracy for class 3: 88.90%\n",
            "Accuracy for class 4: 76.70%\n",
            "Accuracy for class 5: 97.40%\n",
            "Accuracy for class 6: 78.60%\n",
            "Accuracy for class 7: 95.20%\n",
            "Accuracy for class 8: 87.70%\n",
            "Accuracy for class 9: 96.70%\n",
            "Epoch [4/10], Step [100/1875], Loss: 0.2050, Accuracy: 92.50%\n",
            "Epoch [4/10], Step [200/1875], Loss: 0.2151, Accuracy: 92.33%\n",
            "Epoch [4/10], Step [300/1875], Loss: 0.2092, Accuracy: 92.60%\n",
            "Epoch [4/10], Step [400/1875], Loss: 0.2147, Accuracy: 92.49%\n",
            "Epoch [4/10], Step [500/1875], Loss: 0.1944, Accuracy: 92.56%\n",
            "Epoch [4/10], Step [600/1875], Loss: 0.2108, Accuracy: 92.56%\n",
            "Epoch [4/10], Step [700/1875], Loss: 0.2035, Accuracy: 92.57%\n",
            "Epoch [4/10], Step [800/1875], Loss: 0.1918, Accuracy: 92.64%\n",
            "Epoch [4/10], Step [900/1875], Loss: 0.2211, Accuracy: 92.57%\n",
            "Epoch [4/10], Step [1000/1875], Loss: 0.2063, Accuracy: 92.57%\n",
            "Epoch [4/10], Step [1100/1875], Loss: 0.2337, Accuracy: 92.46%\n",
            "Epoch [4/10], Step [1200/1875], Loss: 0.2121, Accuracy: 92.48%\n",
            "Epoch [4/10], Step [1300/1875], Loss: 0.2296, Accuracy: 92.45%\n",
            "Epoch [4/10], Step [1400/1875], Loss: 0.2019, Accuracy: 92.49%\n",
            "Epoch [4/10], Step [1500/1875], Loss: 0.1967, Accuracy: 92.52%\n",
            "Epoch [4/10], Step [1600/1875], Loss: 0.1804, Accuracy: 92.58%\n",
            "Epoch [4/10], Step [1700/1875], Loss: 0.2299, Accuracy: 92.54%\n",
            "Epoch [4/10], Step [1800/1875], Loss: 0.2052, Accuracy: 92.53%\n",
            "Test Accuracy after Epoch 4: 90.29%\n",
            "\n",
            "Accuracy for class 0: 84.10%\n",
            "Accuracy for class 1: 98.10%\n",
            "Accuracy for class 2: 90.00%\n",
            "Accuracy for class 3: 92.10%\n",
            "Accuracy for class 4: 80.80%\n",
            "Accuracy for class 5: 98.50%\n",
            "Accuracy for class 6: 71.70%\n",
            "Accuracy for class 7: 95.10%\n",
            "Accuracy for class 8: 95.90%\n",
            "Accuracy for class 9: 96.60%\n",
            "Epoch [5/10], Step [100/1875], Loss: 0.1783, Accuracy: 93.28%\n",
            "Epoch [5/10], Step [200/1875], Loss: 0.1711, Accuracy: 93.61%\n",
            "Epoch [5/10], Step [300/1875], Loss: 0.1616, Accuracy: 93.74%\n",
            "Epoch [5/10], Step [400/1875], Loss: 0.1609, Accuracy: 93.88%\n",
            "Epoch [5/10], Step [500/1875], Loss: 0.1679, Accuracy: 93.86%\n",
            "Epoch [5/10], Step [600/1875], Loss: 0.1567, Accuracy: 93.95%\n",
            "Epoch [5/10], Step [700/1875], Loss: 0.1904, Accuracy: 93.84%\n",
            "Epoch [5/10], Step [800/1875], Loss: 0.1628, Accuracy: 93.93%\n",
            "Epoch [5/10], Step [900/1875], Loss: 0.1563, Accuracy: 94.02%\n",
            "Epoch [5/10], Step [1000/1875], Loss: 0.1858, Accuracy: 93.97%\n",
            "Epoch [5/10], Step [1100/1875], Loss: 0.2000, Accuracy: 93.92%\n",
            "Epoch [5/10], Step [1200/1875], Loss: 0.1768, Accuracy: 93.92%\n",
            "Epoch [5/10], Step [1300/1875], Loss: 0.1788, Accuracy: 93.92%\n",
            "Epoch [5/10], Step [1400/1875], Loss: 0.1931, Accuracy: 93.83%\n",
            "Epoch [5/10], Step [1500/1875], Loss: 0.1878, Accuracy: 93.81%\n",
            "Epoch [5/10], Step [1600/1875], Loss: 0.1814, Accuracy: 93.82%\n",
            "Epoch [5/10], Step [1700/1875], Loss: 0.1956, Accuracy: 93.80%\n",
            "Epoch [5/10], Step [1800/1875], Loss: 0.1698, Accuracy: 93.79%\n",
            "Test Accuracy after Epoch 5: 91.18%\n",
            "\n",
            "Accuracy for class 0: 90.00%\n",
            "Accuracy for class 1: 97.50%\n",
            "Accuracy for class 2: 87.30%\n",
            "Accuracy for class 3: 91.40%\n",
            "Accuracy for class 4: 87.30%\n",
            "Accuracy for class 5: 98.00%\n",
            "Accuracy for class 6: 70.70%\n",
            "Accuracy for class 7: 94.70%\n",
            "Accuracy for class 8: 97.60%\n",
            "Accuracy for class 9: 97.30%\n",
            "Epoch [6/10], Step [100/1875], Loss: 0.1335, Accuracy: 95.09%\n",
            "Epoch [6/10], Step [200/1875], Loss: 0.1496, Accuracy: 94.81%\n",
            "Epoch [6/10], Step [300/1875], Loss: 0.1505, Accuracy: 94.81%\n",
            "Epoch [6/10], Step [400/1875], Loss: 0.1319, Accuracy: 95.04%\n",
            "Epoch [6/10], Step [500/1875], Loss: 0.1652, Accuracy: 94.90%\n",
            "Epoch [6/10], Step [600/1875], Loss: 0.1615, Accuracy: 94.82%\n",
            "Epoch [6/10], Step [700/1875], Loss: 0.1522, Accuracy: 94.72%\n",
            "Epoch [6/10], Step [800/1875], Loss: 0.1653, Accuracy: 94.67%\n",
            "Epoch [6/10], Step [900/1875], Loss: 0.1403, Accuracy: 94.73%\n",
            "Epoch [6/10], Step [1000/1875], Loss: 0.1425, Accuracy: 94.70%\n",
            "Epoch [6/10], Step [1100/1875], Loss: 0.1492, Accuracy: 94.67%\n",
            "Epoch [6/10], Step [1200/1875], Loss: 0.1377, Accuracy: 94.71%\n",
            "Epoch [6/10], Step [1300/1875], Loss: 0.1619, Accuracy: 94.70%\n",
            "Epoch [6/10], Step [1400/1875], Loss: 0.1884, Accuracy: 94.66%\n",
            "Epoch [6/10], Step [1500/1875], Loss: 0.1651, Accuracy: 94.63%\n",
            "Epoch [6/10], Step [1600/1875], Loss: 0.1415, Accuracy: 94.64%\n",
            "Epoch [6/10], Step [1700/1875], Loss: 0.1386, Accuracy: 94.70%\n",
            "Epoch [6/10], Step [1800/1875], Loss: 0.1607, Accuracy: 94.69%\n",
            "Test Accuracy after Epoch 6: 91.29%\n",
            "\n",
            "Accuracy for class 0: 87.30%\n",
            "Accuracy for class 1: 97.90%\n",
            "Accuracy for class 2: 86.50%\n",
            "Accuracy for class 3: 86.40%\n",
            "Accuracy for class 4: 88.70%\n",
            "Accuracy for class 5: 97.50%\n",
            "Accuracy for class 6: 77.20%\n",
            "Accuracy for class 7: 98.40%\n",
            "Accuracy for class 8: 98.40%\n",
            "Accuracy for class 9: 94.60%\n",
            "Epoch [7/10], Step [100/1875], Loss: 0.1182, Accuracy: 95.84%\n",
            "Epoch [7/10], Step [200/1875], Loss: 0.1291, Accuracy: 95.59%\n",
            "Epoch [7/10], Step [300/1875], Loss: 0.1244, Accuracy: 95.52%\n",
            "Epoch [7/10], Step [400/1875], Loss: 0.1220, Accuracy: 95.53%\n",
            "Epoch [7/10], Step [500/1875], Loss: 0.1215, Accuracy: 95.51%\n",
            "Epoch [7/10], Step [600/1875], Loss: 0.1184, Accuracy: 95.58%\n",
            "Epoch [7/10], Step [700/1875], Loss: 0.1489, Accuracy: 95.53%\n",
            "Epoch [7/10], Step [800/1875], Loss: 0.1382, Accuracy: 95.46%\n",
            "Epoch [7/10], Step [900/1875], Loss: 0.1411, Accuracy: 95.40%\n",
            "Epoch [7/10], Step [1000/1875], Loss: 0.1218, Accuracy: 95.41%\n",
            "Epoch [7/10], Step [1100/1875], Loss: 0.1480, Accuracy: 95.39%\n",
            "Epoch [7/10], Step [1200/1875], Loss: 0.1295, Accuracy: 95.40%\n",
            "Epoch [7/10], Step [1300/1875], Loss: 0.1324, Accuracy: 95.39%\n",
            "Epoch [7/10], Step [1400/1875], Loss: 0.1483, Accuracy: 95.35%\n",
            "Epoch [7/10], Step [1500/1875], Loss: 0.1667, Accuracy: 95.29%\n",
            "Epoch [7/10], Step [1600/1875], Loss: 0.1864, Accuracy: 95.24%\n",
            "Epoch [7/10], Step [1700/1875], Loss: 0.1947, Accuracy: 95.20%\n",
            "Epoch [7/10], Step [1800/1875], Loss: 0.1402, Accuracy: 95.19%\n",
            "Test Accuracy after Epoch 7: 89.36%\n",
            "\n",
            "Accuracy for class 0: 87.50%\n",
            "Accuracy for class 1: 97.80%\n",
            "Accuracy for class 2: 93.20%\n",
            "Accuracy for class 3: 89.80%\n",
            "Accuracy for class 4: 73.60%\n",
            "Accuracy for class 5: 97.20%\n",
            "Accuracy for class 6: 69.80%\n",
            "Accuracy for class 7: 87.80%\n",
            "Accuracy for class 8: 98.30%\n",
            "Accuracy for class 9: 98.60%\n",
            "Epoch [8/10], Step [100/1875], Loss: 0.1312, Accuracy: 94.97%\n",
            "Epoch [8/10], Step [200/1875], Loss: 0.1078, Accuracy: 95.62%\n",
            "Epoch [8/10], Step [300/1875], Loss: 0.1249, Accuracy: 95.75%\n",
            "Epoch [8/10], Step [400/1875], Loss: 0.1105, Accuracy: 95.86%\n",
            "Epoch [8/10], Step [500/1875], Loss: 0.1085, Accuracy: 95.97%\n",
            "Epoch [8/10], Step [600/1875], Loss: 0.1048, Accuracy: 96.03%\n",
            "Epoch [8/10], Step [700/1875], Loss: 0.1079, Accuracy: 96.07%\n",
            "Epoch [8/10], Step [800/1875], Loss: 0.0952, Accuracy: 96.06%\n",
            "Epoch [8/10], Step [900/1875], Loss: 0.1149, Accuracy: 96.06%\n",
            "Epoch [8/10], Step [1000/1875], Loss: 0.1563, Accuracy: 95.98%\n",
            "Epoch [8/10], Step [1100/1875], Loss: 0.1119, Accuracy: 96.04%\n",
            "Epoch [8/10], Step [1200/1875], Loss: 0.0971, Accuracy: 96.07%\n",
            "Epoch [8/10], Step [1300/1875], Loss: 0.1031, Accuracy: 96.07%\n",
            "Epoch [8/10], Step [1400/1875], Loss: 0.1175, Accuracy: 96.05%\n",
            "Epoch [8/10], Step [1500/1875], Loss: 0.1091, Accuracy: 96.06%\n",
            "Epoch [8/10], Step [1600/1875], Loss: 0.1147, Accuracy: 96.08%\n",
            "Epoch [8/10], Step [1700/1875], Loss: 0.1231, Accuracy: 96.07%\n",
            "Epoch [8/10], Step [1800/1875], Loss: 0.1131, Accuracy: 96.07%\n",
            "Test Accuracy after Epoch 8: 90.39%\n",
            "\n",
            "Accuracy for class 0: 89.50%\n",
            "Accuracy for class 1: 97.70%\n",
            "Accuracy for class 2: 85.20%\n",
            "Accuracy for class 3: 82.70%\n",
            "Accuracy for class 4: 83.20%\n",
            "Accuracy for class 5: 99.00%\n",
            "Accuracy for class 6: 76.60%\n",
            "Accuracy for class 7: 96.80%\n",
            "Accuracy for class 8: 98.20%\n",
            "Accuracy for class 9: 95.00%\n",
            "Epoch [9/10], Step [100/1875], Loss: 0.0983, Accuracy: 96.41%\n",
            "Epoch [9/10], Step [200/1875], Loss: 0.0994, Accuracy: 96.38%\n",
            "Epoch [9/10], Step [300/1875], Loss: 0.1127, Accuracy: 96.29%\n",
            "Epoch [9/10], Step [400/1875], Loss: 0.1123, Accuracy: 96.28%\n",
            "Epoch [9/10], Step [500/1875], Loss: 0.0954, Accuracy: 96.38%\n",
            "Epoch [9/10], Step [600/1875], Loss: 0.1073, Accuracy: 96.34%\n",
            "Epoch [9/10], Step [700/1875], Loss: 0.1091, Accuracy: 96.35%\n",
            "Epoch [9/10], Step [800/1875], Loss: 0.1135, Accuracy: 96.34%\n",
            "Epoch [9/10], Step [900/1875], Loss: 0.1038, Accuracy: 96.38%\n",
            "Epoch [9/10], Step [1000/1875], Loss: 0.1280, Accuracy: 96.38%\n",
            "Epoch [9/10], Step [1100/1875], Loss: 0.1181, Accuracy: 96.36%\n",
            "Epoch [9/10], Step [1200/1875], Loss: 0.1331, Accuracy: 96.32%\n",
            "Epoch [9/10], Step [1300/1875], Loss: 0.1371, Accuracy: 96.24%\n",
            "Epoch [9/10], Step [1400/1875], Loss: 0.1135, Accuracy: 96.23%\n",
            "Epoch [9/10], Step [1500/1875], Loss: 0.1444, Accuracy: 96.18%\n",
            "Epoch [9/10], Step [1600/1875], Loss: 0.1324, Accuracy: 96.15%\n",
            "Epoch [9/10], Step [1700/1875], Loss: 0.1072, Accuracy: 96.16%\n",
            "Epoch [9/10], Step [1800/1875], Loss: 0.1327, Accuracy: 96.14%\n",
            "Test Accuracy after Epoch 9: 91.43%\n",
            "\n",
            "Accuracy for class 0: 87.50%\n",
            "Accuracy for class 1: 97.10%\n",
            "Accuracy for class 2: 83.30%\n",
            "Accuracy for class 3: 92.50%\n",
            "Accuracy for class 4: 85.30%\n",
            "Accuracy for class 5: 98.80%\n",
            "Accuracy for class 6: 78.50%\n",
            "Accuracy for class 7: 96.30%\n",
            "Accuracy for class 8: 97.70%\n",
            "Accuracy for class 9: 97.30%\n",
            "Epoch [10/10], Step [100/1875], Loss: 0.0855, Accuracy: 97.16%\n",
            "Epoch [10/10], Step [200/1875], Loss: 0.0846, Accuracy: 97.11%\n",
            "Epoch [10/10], Step [300/1875], Loss: 0.0894, Accuracy: 97.05%\n",
            "Epoch [10/10], Step [400/1875], Loss: 0.1167, Accuracy: 96.89%\n",
            "Epoch [10/10], Step [500/1875], Loss: 0.0901, Accuracy: 96.82%\n",
            "Epoch [10/10], Step [600/1875], Loss: 0.0880, Accuracy: 96.88%\n",
            "Epoch [10/10], Step [700/1875], Loss: 0.0815, Accuracy: 96.96%\n",
            "Epoch [10/10], Step [800/1875], Loss: 0.1135, Accuracy: 96.87%\n",
            "Epoch [10/10], Step [900/1875], Loss: 0.0876, Accuracy: 96.86%\n",
            "Epoch [10/10], Step [1000/1875], Loss: 0.1187, Accuracy: 96.75%\n",
            "Epoch [10/10], Step [1100/1875], Loss: 0.1070, Accuracy: 96.69%\n",
            "Epoch [10/10], Step [1200/1875], Loss: 0.1125, Accuracy: 96.66%\n",
            "Epoch [10/10], Step [1300/1875], Loss: 0.1202, Accuracy: 96.59%\n",
            "Epoch [10/10], Step [1400/1875], Loss: 0.0874, Accuracy: 96.62%\n",
            "Epoch [10/10], Step [1500/1875], Loss: 0.0875, Accuracy: 96.66%\n",
            "Epoch [10/10], Step [1600/1875], Loss: 0.0978, Accuracy: 96.68%\n",
            "Epoch [10/10], Step [1700/1875], Loss: 0.1114, Accuracy: 96.69%\n",
            "Epoch [10/10], Step [1800/1875], Loss: 0.1102, Accuracy: 96.66%\n",
            "Test Accuracy after Epoch 10: 91.06%\n",
            "\n",
            "Accuracy for class 0: 89.00%\n",
            "Accuracy for class 1: 97.90%\n",
            "Accuracy for class 2: 82.90%\n",
            "Accuracy for class 3: 91.20%\n",
            "Accuracy for class 4: 86.40%\n",
            "Accuracy for class 5: 98.20%\n",
            "Accuracy for class 6: 75.00%\n",
            "Accuracy for class 7: 94.80%\n",
            "Accuracy for class 8: 97.40%\n",
            "Accuracy for class 9: 97.80%\n",
            "Обучение завершено!\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Гиперпараметры\n",
        "learning_rate = 0.003\n",
        "num_epochs = 10\n",
        "\n",
        "# Функция потерь и оптимизатор\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_task_1.parameters(), lr=learning_rate)\n",
        "\n",
        "# Цикл обучения\n",
        "for epoch in range(num_epochs):\n",
        "    model_task_1.train()  # Перевод модели в режим обучения\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for i, (images, labels) in enumerate(train_data_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Обнуление градиентов\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Прямой проход\n",
        "        outputs = model_task_1(images)\n",
        "\n",
        "        # Вычисление потерь\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Обратное распространение ошибки\n",
        "        loss.backward()\n",
        "\n",
        "        # Шаг оптимизации\n",
        "        optimizer.step()\n",
        "\n",
        "        # Сбор статистики для вывода\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        if (i + 1) % 100 == 0:  # Вывод каждые 100 батчей\n",
        "            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_data_loader)}], '\n",
        "                  f'Loss: {running_loss / 100:.4f}, Accuracy: {100 * correct / total:.2f}%')\n",
        "            running_loss = 0.0\n",
        "\n",
        "    # Оценка на тестовых данных\n",
        "    model_task_1.eval()  # Перевод модели в режим оценки\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():  # Отключение вычисления градиентов\n",
        "        for images, labels in test_data_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model_task_1(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    # Вычисление матрицы ошибок\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
        "\n",
        "    print(f'Test Accuracy after Epoch {epoch + 1}: {100 * sum(class_accuracy) / 10:.2f}%\\n')\n",
        "    for i, acc in enumerate(class_accuracy):\n",
        "        print(f'Accuracy for class {i}: {100 * acc:.2f}%')\n",
        "\n",
        "print(\"Обучение завершено!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zce7gt1gSq-"
      },
      "source": [
        "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usswrWYOgSq-"
      },
      "source": [
        "Оценим качество классификации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "Xua3TVZHgSq-",
        "outputId": "a29c77f3-9bbd-4ac1-edfb-f593ea9da2b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.97557\n"
          ]
        }
      ],
      "source": [
        "train_acc_task_1 = get_accuracy(model_task_1, train_data_loader)\n",
        "print(f\"Neural network accuracy on train set: {train_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "l9KEKXBxgSq-",
        "outputId": "8e571d3d-c6d8-4086-b3cf-cc8d13b2d576",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on test set: 0.9106\n"
          ]
        }
      ],
      "source": [
        "test_acc_task_1 = get_accuracy(model_task_1, test_data_loader)\n",
        "print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oyhmMobgSq_"
      },
      "source": [
        "Проверка, что необходимые пороги пройдены:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "OAIrURCEgSq_"
      },
      "outputs": [],
      "source": [
        "assert test_acc_task_1 >= 0.885, \"Train accuracy is below 0.885 threshold\"\n",
        "assert (\n",
        "    train_acc_task_1 >= 0.905\n",
        "), \"Train accuracy is below 0.905 while test accuracy is fine. We recommend to check your model and data flow\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjt8vG4nfAvX"
      },
      "source": [
        "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_1`, а файл `hw_fmnist_data_dict.npy` находится в той же директории, что и ноутбук (он доступен в репозитории)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "l9q8lHMifAvX",
        "outputId": "db51a89b-b26c-4076-9b7f-72101ffba832",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to `submission_dict_fmnist_task_1.json`\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_fmnist_data_dict.npy\"\n",
        "), \"Please, download `hw_fmnist_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "loaded_data_dict = np.load(\"hw_fmnist_data_dict.npy\", allow_pickle=True)\n",
        "\n",
        "submission_dict = {\n",
        "    \"train_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
        "    ),\n",
        "    \"test_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
        "    ),\n",
        "}\n",
        "\n",
        "with open(\"submission_dict_fmnist_task_1.json\", \"w\") as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print(\"File saved to `submission_dict_fmnist_task_1.json`\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "II4KasGifAvX"
      },
      "source": [
        "### Сдача задания\n",
        "Сдайте сгенерированный файл в соответствующую задачу в соревновании, а именно:\n",
        "    \n",
        "* `submission_dict_fmnist_task_1.json` в задачу Separation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtWnYAN_gSrA"
      },
      "source": [
        "На этом задание завершено. Поздравляем!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "21499ab2a6726e29f7050b76af0e9680227e613293d630ba279de7ebdfad9cae"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}